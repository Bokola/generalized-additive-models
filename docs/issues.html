<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Generalized Additive Models</title>
  <meta name="description" content="Generalized Additive Models">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Generalized Additive Models" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://m-clark.github.io/generalized-additive-models" />
  <meta property="og:image" content="https://m-clark.github.io/generalized-additive-modelsimg/nineteeneightyR.png" />
  <meta property="og:description" content="Generalized Additive Models" />
  <meta name="github-repo" content="m-clark/" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Generalized Additive Models" />
  
  <meta name="twitter:description" content="Generalized Additive Models" />
  <meta name="twitter:image" content="https://m-clark.github.io/generalized-additive-modelsimg/nineteeneightyR.png" />



<meta name="date" content="2018-03-10">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  <link rel="shortcut icon" href="img/R.ico" type="image/x-icon">
<link rel="prev" href="application-using-r.html">
<link rel="next" href="other-approaches.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.0/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.7.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotlyjs-1.29.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotlyjs-1.29.2/plotly-latest.min.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="css/tufte.css" type="text/css" />
<link rel="stylesheet" href="css/standard_html.css" type="text/css" />
<link rel="stylesheet" href="css/book.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class='before'><a href="https://m-clark.github.io/">Generalized Additive Models</a></li>

<li class="divider"></li>
<li><a href="index.html#section"></a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#beyond-the-general-linear-model-i"><i class="fa fa-check"></i>Beyond the General Linear Model I</a><ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#general-linear-model"><i class="fa fa-check"></i>General Linear Model</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#generalized-linear-model"><i class="fa fa-check"></i>Generalized Linear Model</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#generalized-additive-model"><i class="fa fa-check"></i>Generalized Additive Model</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#beyond-the-general-linear-model-ii"><i class="fa fa-check"></i>Beyond the General Linear Model II</a><ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#fitting-the-standard-linear-model"><i class="fa fa-check"></i>Fitting the Standard Linear Model</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#polynomial-regression"><i class="fa fa-check"></i>Polynomial Regression</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#scatterplot-smoothing"><i class="fa fa-check"></i>Scatterplot Smoothing</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#generalized-additive-models"><i class="fa fa-check"></i>Generalized Additive Models</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#summary"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="the-case-for-gams.html"><a href="the-case-for-gams.html"><i class="fa fa-check"></i>The case for GAMs</a><ul>
<li class="chapter" data-level="" data-path="the-case-for-gams.html"><a href="the-case-for-gams.html#why-not-just-use-standard-methods"><i class="fa fa-check"></i>Why not just use standard methods?</a></li>
<li class="chapter" data-level="" data-path="the-case-for-gams.html"><a href="the-case-for-gams.html#heteroscedasticity-non-normality-etc."><i class="fa fa-check"></i>Heteroscedasticity, non-normality etc.</a></li>
<li class="chapter" data-level="" data-path="the-case-for-gams.html"><a href="the-case-for-gams.html#polynomial-regression-1"><i class="fa fa-check"></i>Polynomial Regression</a><ul>
<li class="chapter" data-level="" data-path="the-case-for-gams.html"><a href="the-case-for-gams.html#a-more-complex-relationship"><i class="fa fa-check"></i>A more complex relationship</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="building-up-to-gams.html"><a href="building-up-to-gams.html"><i class="fa fa-check"></i>Building up to GAMs</a><ul>
<li class="chapter" data-level="" data-path="building-up-to-gams.html"><a href="building-up-to-gams.html#piecewise-polynomial"><i class="fa fa-check"></i>Piecewise polynomial</a></li>
<li class="chapter" data-level="" data-path="building-up-to-gams.html"><a href="building-up-to-gams.html#what-is-a-gam"><i class="fa fa-check"></i>What is a GAM?</a></li>
<li class="chapter" data-level="" data-path="building-up-to-gams.html"><a href="building-up-to-gams.html#polynomial-spline"><i class="fa fa-check"></i>Polynomial spline</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="application-using-r.html"><a href="application-using-r.html"><i class="fa fa-check"></i>Application Using R</a><ul>
<li class="chapter" data-level="" data-path="application-using-r.html"><a href="application-using-r.html#initial-examination"><i class="fa fa-check"></i>Initial Examination</a></li>
<li class="chapter" data-level="" data-path="application-using-r.html"><a href="application-using-r.html#single-predictor"><i class="fa fa-check"></i>Single Predictor</a><ul>
<li class="chapter" data-level="" data-path="application-using-r.html"><a href="application-using-r.html#linear-fit"><i class="fa fa-check"></i>Linear Fit</a></li>
<li class="chapter" data-level="" data-path="application-using-r.html"><a href="application-using-r.html#gam"><i class="fa fa-check"></i>GAM</a></li>
<li class="chapter" data-level="" data-path="application-using-r.html"><a href="application-using-r.html#graphical-display"><i class="fa fa-check"></i>Graphical Display</a></li>
<li class="chapter" data-level="" data-path="application-using-r.html"><a href="application-using-r.html#model-comparison"><i class="fa fa-check"></i>Model Comparison</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="application-using-r.html"><a href="application-using-r.html#multiple-predictors"><i class="fa fa-check"></i>Multiple Predictors</a><ul>
<li class="chapter" data-level="" data-path="application-using-r.html"><a href="application-using-r.html#linear-fit-1"><i class="fa fa-check"></i>Linear Fit</a></li>
<li class="chapter" data-level="" data-path="application-using-r.html"><a href="application-using-r.html#gam-1"><i class="fa fa-check"></i>GAM</a></li>
<li class="chapter" data-level="" data-path="application-using-r.html"><a href="application-using-r.html#graphical-display-1"><i class="fa fa-check"></i>Graphical Display</a></li>
<li class="chapter" data-level="" data-path="application-using-r.html"><a href="application-using-r.html#model-comparison-1"><i class="fa fa-check"></i>Model Comparison</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="issues.html"><a href="issues.html"><i class="fa fa-check"></i>Issues</a><ul>
<li class="chapter" data-level="" data-path="issues.html"><a href="issues.html#estimation"><i class="fa fa-check"></i>Estimation</a><ul>
<li class="chapter" data-level="" data-path="issues.html"><a href="issues.html#shrinkage-variable-selection"><i class="fa fa-check"></i>Shrinkage &amp; Variable Selection</a></li>
<li class="chapter" data-level="" data-path="issues.html"><a href="issues.html#effective-degrees-of-freedom-again"><i class="fa fa-check"></i>Effective degrees of freedom again</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="issues.html"><a href="issues.html#choice-of-smoothing-function"><i class="fa fa-check"></i>Choice of Smoothing Function</a></li>
<li class="chapter" data-level="" data-path="issues.html"><a href="issues.html#diagnostics"><i class="fa fa-check"></i>Diagnostics</a><ul>
<li class="chapter" data-level="" data-path="issues.html"><a href="issues.html#concurvity"><i class="fa fa-check"></i>Concurvity</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="issues.html"><a href="issues.html#prediction"><i class="fa fa-check"></i>Prediction</a></li>
<li class="chapter" data-level="" data-path="issues.html"><a href="issues.html#model-comparison-revisited"><i class="fa fa-check"></i>Model Comparison Revisited</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="other-approaches.html"><a href="other-approaches.html"><i class="fa fa-check"></i>Other Approaches</a><ul>
<li class="chapter" data-level="" data-path="other-approaches.html"><a href="other-approaches.html#other-nonlinear-modeling-approaches"><i class="fa fa-check"></i>Other Nonlinear Modeling Approaches</a><ul>
<li class="chapter" data-level="" data-path="other-approaches.html"><a href="other-approaches.html#known-form"><i class="fa fa-check"></i>Known Form</a></li>
<li class="chapter" data-level="" data-path="other-approaches.html"><a href="other-approaches.html#response-transformation"><i class="fa fa-check"></i>Response Transformation</a></li>
<li class="chapter" data-level="" data-path="other-approaches.html"><a href="other-approaches.html#the-black-box"><i class="fa fa-check"></i>The Black Box</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="other-approaches.html"><a href="other-approaches.html#extensions"><i class="fa fa-check"></i>Extensions</a><ul>
<li class="chapter" data-level="" data-path="other-approaches.html"><a href="other-approaches.html#other-gams"><i class="fa fa-check"></i>Other GAMs</a></li>
<li class="chapter" data-level="" data-path="other-approaches.html"><a href="other-approaches.html#reproducing-kernel-hilbert-space"><i class="fa fa-check"></i>Reproducing Kernel Hilbert Space</a></li>
<li class="chapter" data-level="" data-path="other-approaches.html"><a href="other-approaches.html#gaussian-processes"><i class="fa fa-check"></i>Gaussian Processes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="concluding-remarks.html"><a href="concluding-remarks.html"><i class="fa fa-check"></i>Concluding remarks</a></li>
<li class="chapter" data-level="" data-path="technical-details.html"><a href="technical-details.html"><i class="fa fa-check"></i>Technical details</a><ul>
<li class="chapter" data-level="" data-path="technical-details.html"><a href="technical-details.html#gam-2"><i class="fa fa-check"></i>GAM</a><ul>
<li class="chapter" data-level="" data-path="technical-details.html"><a href="technical-details.html#penalized-regression"><i class="fa fa-check"></i>Penalized regression</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="technical-details.html"><a href="technical-details.html#a-detailed-example"><i class="fa fa-check"></i>A detailed example</a><ul>
<li class="chapter" data-level="" data-path="technical-details.html"><a href="technical-details.html#preview-of-other-bases"><i class="fa fa-check"></i>Preview of other bases</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="technical-details.html"><a href="technical-details.html#the-number-of-knots-and-where-to-put-them"><i class="fa fa-check"></i>The number of knots and where to put them</a></li>
<li class="chapter" data-level="" data-path="technical-details.html"><a href="technical-details.html#interpreting-output-for-smooth-terms"><i class="fa fa-check"></i>Interpreting output for smooth terms</a><ul>
<li class="chapter" data-level="" data-path="technical-details.html"><a href="technical-details.html#effective-degrees-of-freedom"><i class="fa fa-check"></i>Effective degrees of freedom</a></li>
<li class="chapter" data-level="" data-path="technical-details.html"><a href="technical-details.html#deviance-explained"><i class="fa fa-check"></i>Deviance explained</a></li>
<li class="chapter" data-level="" data-path="technical-details.html"><a href="technical-details.html#visual-depiction"><i class="fa fa-check"></i>Visual depiction</a></li>
<li class="chapter" data-level="" data-path="technical-details.html"><a href="technical-details.html#examining-first-derivatives"><i class="fa fa-check"></i>Examining first derivatives</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a><ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#r-packages"><i class="fa fa-check"></i>R packages</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#time-and-space"><i class="fa fa-check"></i>Time and Space</a><ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#time"><i class="fa fa-check"></i>Time</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#space"><i class="fa fa-check"></i>Space</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li class='after'><a href="https://m-clark.github.io/"><img src="img/mc.png" style="width:50%; padding:0px 0; display:block; margin: 0 auto;" alt="MC logo"></a></li>
<li class='after'><a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="width:50%; border-width:0; display:block; margin: 0 auto;" src="img/ccbysa.png" /></a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><span style="color:#0085A1; font-size:5rem">Generalized Additive Models</span></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="issues" class="section level1">
<h1>Issues</h1>
<div id="estimation" class="section level2">
<h2>Estimation</h2>
<p><span class="newthought">As noted previously</span>, estimation of GAMs in the mgcv package is conducted via a penalized likelihood approach. More detail can be found in the <a href="technical-details.html#technical-details">technical section</a>, but conceptually this amounts to fitting the following model:</p>
<p><span class="math display">\[g(\mu) = f(x_1) + f(x_2) ... f(x_j)\]</span></p>
<p>But note that each smooth has its own model matrix made up of the basis functions. So for each smooth covariate <span class="math inline">\(j\)</span> we have:</p>
<p><span class="math display">\[f_j = \tilde{X}_j \tilde{\beta}_j\]</span></p>
<p>Given a matrix of coefficients <span class="math inline">\(S\)</span>, we can more formally note a penalized likelihood function:</p>
<p><span class="math display">\[l_p(\beta)=\displaystyle l(\beta) - \frac{1}{2}\sum_j\lambda_j \beta^\mathrm{T} S_j\beta\]</span></p>
<p>where <span class="math inline">\(l(\beta)\)</span> is the usual GLM likelihood function, and <span class="math inline">\(\lambda_j\)</span> are the smoothing parameters. The part of the function including <span class="math inline">\(\lambda\)</span> penalizes curvature in the function, where <span class="math inline">\(\lambda\)</span> establishes a trade-off between the goodness of fit and the smoothness, and such an approach will allow for less overfitting. As <span class="math inline">\(\lambda\rightarrow\infty\)</span>, we’d have a linear estimate for <span class="math inline">\(f_j\)</span>, while <span class="math inline">\(\lambda = 0\)</span> would allow any <span class="math inline">\(f\)</span> that interpolates the data<a href="#fn19" class="footnoteRef" id="fnref19"><sup>19</sup></a>. Technically we could specify the smoothing parameters explicitly, and the <a href="technical-details.html#a-detailed-example">Appendix</a> has some ‘by-hand’ code taken directly from <span class="citation">Wood (<a href="#ref-wood_generalized_2006">2006</a>)</span> with only slight modifications, where the smoothing parameters are chosen and compared.</p>
<p>Smoothing parameters however are in fact estimated rather than arbitrarily set, and this brings us back to the cross-validation procedure mentioned before. Smoothing parameters are selected which minimize the GCV score by default, though one has other options, e.g. using REML as with mixed models. Note that there are other approaches to estimation such as backfitting, generalized smoothing splines and Bayesian.</p>
<div id="shrinkage-variable-selection" class="section level3">
<h3>Shrinkage &amp; Variable Selection</h3>
<p>Some smooths are such that no matter the smoothing parameter, there will always be non-zero coefficients for the basis functions. An extra penalty may be added such that if the smoothing parameter is large enough, the coefficients will shrink to zero, and some smoothing bases will have such alternative approaches available<a href="#fn20" class="footnoteRef" id="fnref20"><sup>20</sup></a>. In this manner, one can assess whether a predictor is adding anything to the model, i.e. if it’s effective degrees of freedom is near zero, and perhaps use the approach as a variable selection technique.</p>
</div>
<div id="effective-degrees-of-freedom-again" class="section level3">
<h3>Effective degrees of freedom again</h3>
<p>If we define a matrix <span class="math inline">\(F\)</span> that maps the unpenalized estimates of <span class="math inline">\(\beta\)</span> to the penalized estimates such that</p>
<p><span class="math display">\[F = (X^T X + S)^{-1} X^T X\]</span></p>
<p>and note</p>
<p><span class="math display">\[\tilde{\beta} = (X^T X)^{-1} X^T y\]</span> <span class="math display">\[\hat{\beta} = F\tilde{\beta}\]</span></p>
<p>the diagonal elements of <span class="math inline">\(F\)</span> are where the effective degrees of freedom for each covariate come from.</p>
</div>
</div>
<div id="choice-of-smoothing-function" class="section level2">
<h2>Choice of Smoothing Function</h2>
<p>A number of smooths are available with the <span class="pack">mgcv</span> package, and one can learn more via the help file for <span class="func">smooth.terms</span> (<a href="http://www.inside-r.org/r-doc/mgcv/smooth.terms">link</a>). In our models, we have used cubic regression splines and thin plate regression splines (TPRS), the latter being the default for a GAM in this package. As a brief summary, TPRS work well in general in terms of performance and otherwise has some particular advantages, and has a shrinkage alternative available. One should still feel free to play around, particularly when dealing with multiple smooths, where the tensor product smooths would be better for covariates of different scales.</p>
</div>
<div id="diagnostics" class="section level2">
<h2>Diagnostics</h2>
<p>We have some built-in abilities to examine whether there are any particular issues, and we can try it with our second GAM model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## gam.check(mod_gam2, k.rep=1000)</code></pre></div>
<p><img src="GAM_files/figure-html/gam_check-1.svg" width="768" style="display: block; margin: auto;" /></p>
<pre><code>
Method: GCV   Optimizer: magic
Smoothing parameter selection converged after 21 iterations.
The RMS GCV score gradient at convergence was 2.499332e-05 .
The Hessian was positive definite.
Model rank =  28 / 28 

Basis dimension (k) checking results. Low p-value (k-index&lt;1) may
indicate that k is too low, especially if edf is close to k&#39;.

            k&#39;  edf k-index p-value
s(Income) 9.00 7.59    1.26    0.98
s(Edu)    9.00 6.20    1.01    0.49
s(Health) 9.00 1.00    0.90    0.18</code></pre>
<p>The plots are of the sort we’re used to from a typical regression setting, though it’s perhaps a bit difficult to make any grand conclusion based on such a small data set. <span class="marginnote">One can inspect the quantile-quantile plot directly with <span class="func">qq.gam</span>.</span> The printed output on the other hand contains unfamiliar information, but is largely concerned with over-smoothing, and so has tests of whether the basis dimension for a smooth is too low. The p-values are based on simulation, so I bumped up the number with the additional argument. Guidelines are given in the output itself, and at least in this case it does not look like we have an issue. However, if there were a potential problem, it is suggested to double <span class="math inline">\(k\)</span><span class="marginnote"> The <code>k</code> can be set as an argument to <code>s(var1, k=?)</code>.</span> and refit, and if the effective degrees of freedom increases quite a bit you would probably want to go with the updated model<a href="#fn21" class="footnoteRef" id="fnref21"><sup>21</sup></a>.</p>
<p>Given the penalization process, the exact choice of <span class="math inline">\(k\)</span> isn’t too big of a deal, and can be seen as an upper limit to the flexibility of the term. The actual flexibility is determined via the penalization process. However, the defaults are arbitrary. You want to set it large enough to get at the true effect as best as possible, but in some cases computational efficiency will also be of concern. For example, in fairly complex models with many predictors, interactions, etc., it might be worthwhile to reduce <span class="math inline">\(k\)</span> at the outset. The help file for the function <span class="func">choose.k</span> provides another approach to examining <span class="math inline">\(k\)</span> based on the residuals from the model under consideration, and provides other useful information.</p>
<div id="concurvity" class="section level3">
<h3>Concurvity</h3>
<p><span class="emph">Concurvity</span> refers to the generalization of collinearity to the GAM setting<a href="#fn22" class="footnoteRef" id="fnref22"><sup>22</sup></a>. In this case it refers to the situation where a smooth term can be approximated by some combination of the others. It largely results in the same problem as elsewhere, i.e. unstable estimates.</p>
<p>Wood provides three indices related to concurvity via the concurvity function, all range from 0 to 1 with 0 suggesting no problem, and 1 indicating that the function lies entirely in the space of one or more of the other smooth terms. See <code>?concurvity</code> for details.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">concurvity</span>(mod_gam2)</code></pre></div>
<table style="width:82%;">
<colgroup>
<col width="20%" />
<col width="16%" />
<col width="16%" />
<col width="12%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">para</th>
<th align="center">s(Income)</th>
<th align="center">s(Edu)</th>
<th align="center">s(Health)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>worst</strong></td>
<td align="center">2.698e-24</td>
<td align="center">0.9839</td>
<td align="center">0.9651</td>
<td align="center">0.9746</td>
</tr>
<tr class="even">
<td align="center"><strong>observed</strong></td>
<td align="center">2.698e-24</td>
<td align="center">0.7968</td>
<td align="center">0.6116</td>
<td align="center">0.8682</td>
</tr>
<tr class="odd">
<td align="center"><strong>estimate</strong></td>
<td align="center">2.698e-24</td>
<td align="center">0.7611</td>
<td align="center">0.6471</td>
<td align="center">0.7971</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>It should probably come as little surprise that we may have an issue here given the nature of the covariates. We can certainly make assumptions about wealthier nations’ education and health status, for example. What can we do? Collinearity does not lead to biased estimates, only less stable ones, and the inflated variance can potentially be overcome with more data. We certainly can’t do that here as we are dealing with country level data. That may also provide the solution, since there is nothing to generalize to, as we have the population of interest (all countries with PISA scores). In other data settings however, we may need to think hard about what to include in the model to avoid such redundancy, take dimension reduction steps beforehand, or use some other selection technique. For example, if it is the result of having several <a href="time-and-space">time- or spatially- covarying predictors</a>, one might be able retain only those that best capture that effect. However, the <span class="pack">mgcv</span> estimation procedures have been developed with such issues in mind, and one can feel fairly confident in the results even in the presence of concurvity. See <span class="citation">Wood (<a href="#ref-wood2008">2008</a>)</span>.</p>
</div>
</div>
<div id="prediction" class="section level2">
<h2>Prediction</h2>
<p>A previous example used the predict function on the data used to fit the model to obtain fitted values on the response scale. We’d typically use this on new data. I do not cover it, because the functionality is the same as the <span class="func">predict.glm</span> function in base R, and one can just refer to that. It is worth noting again that there is an option, <code>type='lpmatrix'</code>, which will return the actual model matrix by which the coefficients must be pre-multiplied to get the values of the linear predictor at the supplied covariate values. This can be particularly useful towards opening the <a href="other-approaches.html#the-black-box">black box</a> as one learns the technique.</p>
</div>
<div id="model-comparison-revisited" class="section level2">
<h2>Model Comparison Revisited</h2>
<p>We have talked about automated smoothing parameter and term selection, and in general potential models are selected based on estimation of the smoothing parameter. Using an extra penalty to allow coefficients to tend toward zero with the argument <code>select=TRUE</code> is an automatic way to go about it, where some terms could effectively drop out. Otherwise we could compare models GCV/AIC scores<a href="#fn23" class="footnoteRef" id="fnref23"><sup>23</sup></a>, and in general either of these would be viable approaches. Consider the following comparison:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod_1d =<span class="st"> </span><span class="kw">gam</span>(Overall <span class="op">~</span><span class="st"> </span><span class="kw">s</span>(Income) <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(Edu), <span class="dt">data=</span>pisa)
mod_2d =<span class="st"> </span><span class="kw">gam</span>(Overall <span class="op">~</span><span class="st"> </span><span class="kw">te</span>(Income, Edu, <span class="dt">bs=</span><span class="st">&quot;tp&quot;</span>), <span class="dt">data=</span>pisa)
## AIC(mod_1d, mod_2d)</code></pre></div>
<table style="width:40%;">
<colgroup>
<col width="18%" />
<col width="11%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">df</th>
<th align="center">AIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>mod_1d</strong></td>
<td align="center">15.59</td>
<td align="center">476.1</td>
</tr>
<tr class="even">
<td align="center"><strong>mod_2d</strong></td>
<td align="center">13.25</td>
<td align="center">489.7</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>In some cases, we might prefer to be explicit in comparing models with and without particular terms, and we can go about comparing models as we would with a typical GLM analysis of deviance. We have demonstrated this previously using the <span class="func">anova.gam</span> function, where we compared linear fits to a model with an additional smooth function. While we could construct a scenario that is identical to the GLM situation for a statistical comparison, it should be noted that in the usual situation the test is actually an approximation, though it should be close enough when it is appropriate in the first place. The following provides an example that would nest the main effects of Income and Education within the product smooth, i.e. sets their basis dimension and smoothing function to the defaults employed by the tensor product smooth.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod_A =<span class="st"> </span><span class="kw">gam</span>(Overall <span class="op">~</span><span class="st"> </span><span class="kw">s</span>(Income, <span class="dt">bs=</span><span class="st">&quot;cr&quot;</span>, <span class="dt">k=</span><span class="dv">5</span>) <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(Edu, <span class="dt">bs=</span><span class="st">&quot;cr&quot;</span>, <span class="dt">k=</span><span class="dv">5</span>), <span class="dt">data=</span>pisa)
mod_B =<span class="st"> </span><span class="kw">gam</span>(Overall <span class="op">~</span><span class="st"> </span><span class="kw">ti</span>(Income, <span class="dt">bs=</span><span class="st">&quot;cr&quot;</span>, <span class="dt">k=</span><span class="dv">5</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ti</span>(Edu, <span class="dt">bs=</span><span class="st">&quot;cr&quot;</span>, <span class="dt">k=</span><span class="dv">5</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ti</span>(Income, Edu, <span class="dt">bs=</span><span class="st">&#39;cr&#39;</span>), <span class="dt">data=</span>pisa)

## anova(mod_A,mod_B, test=&quot;Chisq&quot;)</code></pre></div>
<table style="width:40%;">
<colgroup>
<col width="18%" />
<col width="11%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">df</th>
<th align="center">AIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>mod_1d</strong></td>
<td align="center">15.59</td>
<td align="center">476.1</td>
</tr>
<tr class="even">
<td align="center"><strong>mod_2d</strong></td>
<td align="center">13.25</td>
<td align="center">489.7</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>Again though, we could have just used the summary output from the second model.</p>
<p>Instances where such a statistical test does not appear to be appropriate within the context of the <span class="mgcv"></span> package are when terms are able to be penalized to zero; in such a case p-values will be much too low. In addition, when comparing GAMs, sometimes the nesting of models would not be so clear when there are multiple smooths involved, and additional steps may need to be taken to make sure they are nested to use the statistical test. We must make sure that each smooth term in the null model has no more effective degrees of freedom than the same term in the alternative, otherwise it’s possible that the model with more terms can have lower effective degrees of freedom but better fit, rendering the test nonsensical. Wood suggests that if such model comparison is the ultimate goal an unpenalized approach<a href="#fn24" class="footnoteRef" id="fnref24"><sup>24</sup></a> would be best to have much confidence in the p-values<a href="#fn25" class="footnoteRef" id="fnref25"><sup>25</sup></a>.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-wood_generalized_2006">
<p>Wood, S. N. 2006. <em>Generalized Additive Models: An Introduction with R</em>. Vol. 66. CRC Press.</p>
</div>
<div id="ref-wood2008">
<p>Wood, Simon N. 2008. “Fast Stable Direct Fitting and Smoothness Selection for Generalized Additive Models.” <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 70 (3). Wiley Online Library: 495–518.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="19">
<li id="fn19"><p>See p. 128, <span class="citation">Wood (<a href="#ref-wood_generalized_2006">2006</a>)</span>, or p. 168 in <span class="citation">Wood (<a href="#ref-wood_generalized_2017">2017</a>)</span>.<a href="issues.html#fnref19">↩</a></p></li>
<li id="fn20"><p>See also, the <code>select</code> argument to the <span class="func">gam</span> function.<a href="issues.html#fnref20">↩</a></p></li>
<li id="fn21"><p>I actually did this for Health, just for demonstration, and there was no change at all; it still reduced to a linear effect.<a href="issues.html#fnref21">↩</a></p></li>
<li id="fn22"><p>The topic is strangely absent in Wood’s text.<a href="issues.html#fnref22">↩</a></p></li>
<li id="fn23"><p>GCV scores are not useful for comparing fits of different families; AIC is still okay though.<a href="issues.html#fnref23">↩</a></p></li>
<li id="fn24"><p>This can be achieved with the argument <code>s(..., fx=T)</code>, although now one has to worry more about the k value used, as very high k will lead to low power.<a href="issues.html#fnref24">↩</a></p></li>
<li id="fn25"><p>One might also examine the <span class="pack">gss</span> package for an ANOVA based approach to generalized smoothing splines.<a href="issues.html#fnref25">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="application-using-r.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="other-approaches.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["twitter", "facebook", "google", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"download": null,
"toc": {
"collapse": "section",
"depth": 2,
"scroll_highlight": true
},
"highlight": "pygments",
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
