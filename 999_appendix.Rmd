# Appendix

## R packages
<span class="newthought">The following is</span> a non-exhaustive list of R packages which contain GAM functionality. Each is linked to the CRAN page for the package.  Note also that several build upon the <span class="pack">mgcv</span> package used for this document.

[brms](http://cran.r-project.org/web/packages/brms/) Allows for Bayesian GAMs via the Stan modeling language (very new implementation).

[CausalGAM](http://cran.r-project.org/web/packages/CausalGAM/) This package implements various estimators for average treatment effects. 

[COZIGAM](http://cran.r-project.org/web/packages/COZIGAM/) Constrained and Unconstrained Zero-Inflated Generalized Additive Models.

[CoxBoost](http://cran.r-project.org/web/packages/CoxBoost/) This package provides routines for fitting Cox models. See also <span class="func">cph</span> in rms package for nonlinear approaches in the survival context.

[gam](http://cran.r-project.org/web/packages/gam/) Functions for fitting and working with generalized additive models.  

[GAMBoost](http://cran.r-project.org/web/packages/GAMBoost/): This package provides routines for fitting generalized linear and and generalized additive models by likelihood based boosting.

[gamboostLSS](http://cran.r-project.org/web/packages/gamboostLSS/): Boosting models for fitting generalized additive models for location, shape and scale (gamLSS models). 

[GAMens](http://cran.r-project.org/web/packages/GAMens/): This package implements the GAMbag, GAMrsm and GAMens ensemble classifiers for binary classification.

[gamlss](http://cran.r-project.org/web/packages/gamlss/): Generalized additive models for location, shape, and scale. 

[gamm4](http://cran.r-project.org/web/packages/gamm4/): Fit generalized additive mixed models via a version of mgcv's gamm function.  

[gammSlice](http://cran.r-project.org/web/packages/gammSlice/): Bayesian fitting and inference for generalized additive mixed models.

[GMMBoost](http://cran.r-project.org/web/packages/GMMBoost/): Likelihood-based Boosting for Generalized mixed models.

[gss](http://cran.r-project.org/web/packages/gss/):  A comprehensive package for structural multivariate function estimation using smoothing splines.

[mboost](http://cran.r-project.org/web/packages/mboost/): Model-Based Boosting. 

[mgcv](http://cran.r-project.org/web/packages/mgcv/): Routines for GAMs and other generalized ridge regression with multiple smoothing parameter selection by GCV, REML or UBRE/AIC. Also GAMMs. 

[VGAM](http://cran.r-project.org/web/packages/VGAM/): Vector generalized linear and additive models, and associated models.


## Time and Space

### Time

A natural setting for GAMs is where there are observations over time. Perhaps we want to examine the trend over time. The SLiM would posit a linear trend, but we often would doubt that is the case.  How would we do this with a GAM?  We can incorporate a covariate representing the time component and add it as a smooth term.  There will be some additional issues though as we will see.

Here I use the data and example at [Gavin Simpon's excellent blog](https://www.fromthebottomoftheheap.net/), though with my own edits, updated data, and different model. The data regards global temperature anomalies, which for some people assume does not exist, but for our purposes is actually in front of our face.


```{r gamtime_setup, echo=c(1:2, 5:8), eval=-(2:3), out.width='40%', fig.asp=.5}
## Global temperatures
gtemp = read.table("https://crudata.uea.ac.uk/cru/data/temperature/HadCRUT4-gl.dat", fill = TRUE)
save(gtemp, file='data/global_temperatures.RData')
load('data/global_temperatures.RData')

## Drop the even rows
gtemp = gtemp %>% drop_na()

## Add colnames
colnames(gtemp) <- c("Year", month.abb, "Annual")

# Create a long format for later; Also set year to start at 0
gtemp_long = gtemp %>% 
  mutate(Year0 = Year-1850) %>% 
  gather(key = Month, value=Anomaly, -Year, -Annual)


gtemp %>% 
  plot_ly(x=~ Year, y=~ Annual) %>% 
  add_lines(x=~Year, y=0, color=I('gray92')) %>% 
  add_lines(color=I('#00aaff'), showlegend=F) %>% 
  theme_plotly()
```

<br>

Fitting a straight line to this would be disastrous, so let's do a GAM. 

```{r gamtime, out.width='40%', fig.asp=.5, echo=1:2, out.width='40%', fig.asp=.5}
hot_gam = gam(Annual ~ s(Year), data=gtemp)
summary(hot_gam)
plotdat = visreg(hot_gam, plot = F)$fit
plotdat %>% 
  plot_ly() %>% 
  add_ribbons(x=~Year, ymin=~visregLwr, ymax =~visregUpr, color=I('#ff5500')) %>% 
  add_markers(x=~Year, y=~Annual, data=gtemp, color=I('#ff5500'), opacity=.5) %>% 
  add_lines(x=~Year, y=~visregFit, color=I('#00aaff'), data=plotdat) %>% 
  theme_plotly() %>% 
  config(displayModeBar=F) %>% 
  layout(showlegend=F,
         xaxis=list(ticklength=10),
         yaxis=list(title='Anomaly'))

# library(ggTimeSeries)
# ggplot_waterfall(dtData = gtemp, 'Year', 'Annual')
```

<br>

We can see that the trend is generally increasing, and has been more or less since the beginning of the 20th century.  We have a remaining issue though. In general, a time series is autocorrelated, correlated with itself over time. We can see this in the following plot.

```{r ar_raw, eval=FALSE}
acf(gtemp$Annual)
```

```{r ar_raw_pretty, echo=FALSE, out.width='40%', fig.asp=.5}
acfdat = acf(gtemp$Annual, 
             lag.max = 25,
             bty='n', 
             lwd=2,
             lty=1,
             ylim=c(-.2,1), 
             xlim=c(0,25),
             col='#ff5500CC',
             ci.col='#00aaff80',
             main='',
             ylab='Autocorrelation',
             col.axis='gray35',
             col.lab='gray35',
             col.main='gray50',
             xaxt='n',
             yaxt='n')
axis(side = 1, col='gray75', col.ticks = 'gray50', col.axis='gray35')
axis(side = 2, col='gray75', col.ticks = 'gray50', col.axis='gray35')
title(main='Autocorrelation of Annual Temperature Anomalies',col.main='gray25') # bc col.main ignored in acf
```

<br>

What the plot shows is the correlation of the values with themselves at different <span class="emph">lags</span>, or time spacings.  Lag 0 is it's correlation with itself, so the value is 1.0.  It's correlation with itself at the previous time point, i.e. lag = 1, is `r round(acfdat$acf[2], 2)`, it's correlation with itself at two time points ago is slightly less, `r round(acfdat$acf[3], 2)`, and the decreasing trend continues slowly.  The dotted lines indicate a 95% confidence interval around zero, meaning that the autocorrelation is still significant 25 years apart.

With our model the issue remains in that there is still autocorrelation among the residuals, at least at lag 1.

```{r ar_res, echo=FALSE, out.width='40%', fig.asp=.5}
acfdat = acf(resid(hot_gam), 
             lag.max = 10,
             bty='n', 
             lwd=2,
             lty=1,
             ylim=c(-.2,1), 
             xlim=c(0,10),
             col='#ff5500CC',
             ci.col='#00aaff80',
             main='',
             ylab='Autocorrelation',
             col.axis='gray35',
             col.lab='gray35',
             col.main='gray50',
             xaxt='n',
             yaxt='n')
axis(side = 1, col='gray75', col.ticks = 'gray50', col.axis='gray35')
axis(side = 2, col='gray75', col.ticks = 'gray50', col.axis='gray35')
title(main='Autocorrelation of Residuals',col.main='gray25') 
```

The practical implications of autocorrelated residuals is that this positive correlation would result in variance estimates that are too low.  However, we can take this into account with a slight tweaking of our model to incorporate such autocorrelation.  For our purposes we'll switch to the <span class="func">gamm</span> function.  It adds additional functionality for generalized additive *mixed* models, though we can just use it for to incorporate autocorrelation of the residuals.  In running this, two sets of output are provided, one in our familiar <span class="objclass">gam</span> model object, and the other as a <span class="objclass">lme</span> object from the <span class="pack">nlme</span> package.

```{r gam_ar}
hot_gam_ar = gamm(Annual ~ s(Year), data=gtemp, correlation=corAR1(form = ~Year))
# summary(hot_gam)
summary(hot_gam_ar$gam)
summary(hot_gam_ar$lme)
```

In the gam output, we see some slight differences but not much (and we wouldn't expect it). From the lme output we can see the estimated autocorrelation value denoted as `Phi`[^Xlme].  Let's see what it does for our fit.

```{r gam_ar_fit, echo=FALSE, fig.show='hide', out.width='40%', fig.asp=.5}
plotdat1 = predict(gamm(Annual ~ s(Year), data=gtemp)$gam, newdata = plotdat %>% select(Year), type = 'response', se=T)
plotdat1 = data_frame(Year= plotdat$Year,
                      fit = plotdat1$fit,
                      upper=fit+2*plotdat1$se,
                      lower=fit-2*plotdat1$se
                      )
plotdat2 = predict(hot_gam_ar$gam, newdata = plotdat %>% select(Year), type='response', se=T)
plotdat2 = data_frame(Year= plotdat$Year,
                      fit = plotdat2$fit,
                      upper=fit+2*plotdat2$se,
                      lower=fit-2*plotdat2$se
                      )

plotdat1 %>% 
  plot_ly() %>% 
  add_ribbons(x=~Year, ymin=~lower, ymax =~upper, color=I('gray75'), data=plotdat1) %>% 
  # add_lines(x=~Year, y=~fit, color=I('gray50'), data=plotdat1) %>% 
  add_ribbons(x=~Year, ymin=~lower, ymax =~upper, color=I('#ff5500'), data=plotdat2) %>% 
  add_lines(x=~Year, y=~fit, color=I('#00aaff'), data=plotdat2) %>% 
  theme_plotly() %>% 
  config(displayModeBar=F) %>% 
  layout(showlegend=F,
         xaxis=list(ticklength=10),
         yaxis=list(title='Anomaly'))
```

<br>

We can in fact see that we were a bit optimistic in the previous fit (non-colored band).  Our new fit is wider at every point[^timefits].  Thus in using a GAM for time-series data, we have the same issues we'd have with standard regression settings, and we'd deal with them in much the same way to get a better sense of the uncertainty in our estimates.

### Space

Consider a data set with latitude and longitude coordinates among other covariates used to model some target variable.  A spatial regression analysis uses an approach to account for spatial covariance among the observation points (e.g. <span class="emph">kriging</span>).  Such an approach is a special case of <span class="emph">Gaussian process</span> which, as we noted, certain types of GAMs can be seen as such also.  As such we can add spatial models to the sorts of models covered by GAMs too.  

When dealing with space, we may have spatial locations of a continuous sort, such as with latitude and longitude, or in a discrete sense, such as regions.  In what follows we'll examine both cases.


#### Continuous

<span class="marginnote">This is based on Peter Ellis' example, which you can find [here](https://ellisp.github.io/blog/2016/08/04/nzcensus-gam-elastic-lm).</span>
Our example will use census data from New Zealand and focus on median income.  It uses the <span class="pack">nzcensus</span> package[^rforeverything] which includes median income, latitude, longitude and several dozen other variables.  The latitude and longitude are actually centroids of the area unit, so this technically could also be used as a discrete example based on the unit.

Let's take an initial peek. <span class="marginnote">This visualization uses <span class="pack">leaflet</span>.</span>

```{r nz_income, eval=T, echo=5:8}
# install the nzcensus package (note it is part of the nzelect GitHub repository):
# devtools::install_github("ellisp/nzelect/pkg2")

library(leaflet)
library(nzcensus)

# remove Chatham Islands 
nz_census <- AreaUnits2013 %>% 
  filter(WGS84Longitude > 0 & !is.na(MedianIncome2013)) %>% 
  rename(lon = WGS84Longitude,
         lat = WGS84Latitude,
         Income = MedianIncome2013) %>% 
  drop_na()

# create colour palette function
pal <- colorQuantile("RdBu", NULL, n = 10)
pal <- colorQuantile(viridis::plasma(n=10, begin = 1, end=0), domain = NULL, n=10)

# create labels for popups
labs <- paste0(nz_census$AU_NAM, " $", format(nz_census$Income, big.mark = ","))

# draw map:
leaflet() %>%
   addProviderTiles("CartoDB.Positron") %>%
   addCircles(lng = nz_census$lon, lat = nz_census$lat,
              color = pal(-nz_census$Income),
              popup = labs,
              radius = 500) %>%
   addLegend(
      pal = pal,
      values = -nz_census$Income,
      title = "Top Quantile of median<br>household income",
      position = "topleft")
```
 
<br>

So we can go ahead and run this predicting median income solely by geography.  We'll use a gaussian process smooth. In addition, we'll allow latitude and longitude to interact.  What the GAM allows us to do is smooth our predictions beyond the points we have in the data to get a more complete picture of income distribution across the whole area. <span class="marginnote">This visualization uses <span class="pack">plotly</span>. In case you're wondering, this was a major ordeal to figure out how to create this plot.</span>

```{r nz_income_gam, echo=1}
nz_gam = gam(Income ~ s(lon, lat, bs='gp'), data=nz_census)
# 
# tt = visreg2d(nz_gam, xvar='lon', yvar='lat', scale='response', nn = 200)[1:3] # for some reason 2d doesn't have a plot= argument so is suppressed with 'hide'
# names(tt) = c('lon', 'lat', 'Income')

# convert map object to sp if needed
# nz_map <- map('world', 'new zealand') %>% 
#   maptools::map2SpatialPolygons(IDs=sapply(strsplit(.$names, ":"), "[", 1L), 
#                                 proj4string=sp::CRS("+proj=longlat +datum=WGS84"))

nz_map_data = map_data("world") %>%
  filter(region == 'New Zealand') %>%
  filter(subregion %in% c('North Island', 'South Island')) %>%  #adding , 'Stewart Island' will show plotly bug
  group_by(group) %>%
  rename(lon = long)


# heatvals = gather(tt$Income %>% data.frame()) %>% 
#   mutate(lon=rep(tt$lon, t=length(tt$lon)),
#          lat=rep(tt$lat, e=length(tt$lon))) %>% 
#   rename(Income=value) %>% 
#   select(-key) %>% 
#   filter(point.in.polygon(.$lon, .$lat, pol.x = nz_map_data$lon, pol.y = nz_map_data$lat)==1) 

# this way can avoid visreg and have a bit more control along wtih point size
heatvals = data_frame(lon=rep(seq(min(nz_census$lon)-4, max(nz_census$lon)+4, length.out = 500), e=500),
                      lat=rep(seq(min(nz_census$lat)-4, max(nz_census$lat)+4, length.out = 500), t=500),
                      Income = predict(nz_gam, newdata = data_frame(lon, lat))) %>% 
  filter(sp::point.in.polygon(.$lon, .$lat, pol.x = nz_map_data$lon, pol.y = nz_map_data$lat)==1) 


blank_layer <- list(
  title = "",
  showgrid = F,
  showticklabels = F,
  zeroline = F)
g <- list(
  scope = 'new zealand',
  showframe = F,
  showland = T,
  landcolor = toRGB(NA)
)
g1 <- c(
  g,
  resolution = 50,
  showcoastlines = T,
  countrycolor = toRGB('gray'),
  coastlinecolor = toRGB('gray'),
  projection = list(type = 'longlat'),
  list(lonaxis = list(range = c(min(heatvals$lon), max(heatvals$lon)))),
  list(lataxis = list(range = c(min(heatvals$lat), max(heatvals$lat)))),
  list(domain = list(x = c(0, 1), y = c(0, 1)))
)

nz_map_data %>% 
  plot_geo(x=~lon, y=~lat) %>% 
  layout(
    title = 'Expected Income',
    geo = g1
  ) %>%
  add_markers(x=~lon, y=~lat, color =~Income, data=heatvals, opacity=.5, colors=viridis::plasma(50), size=I(3))# %>%
```

<br>

Using the gaussian process smooth produces a result that is akin to a very traditional spatial modeling technique called <span class="emph">kriging</span>.



#### Discrete

What about the discrete case, where the spatial *random effect* is based on geographical regions?  This involves a penalty that is based on the adjacency matrix of the regions, where if there are $g$ regions, the adjacency matrix is a $g \times g$ indicator matrix where there is some non-zero value when region i is connected to region j, and 0 otherwise.  In addition an approach similar to that for a random effect is used to incorporate observations belonging to specific regions.  These are sometimes referred to as geoadditive models.

You'll be shocked to know that <span class="pack">mgcv</span> has a smooth construct for this situation as well, `bs='mrf'`, where `mrf` stands for <span class="emph">Markov random field</span>, which is an undirected graph.  Plotting the smooth term is akin to displaying the spatial random effect.

The following shows example code. See the help for `mrf` for more detail.

```{r gamspatdiscrete, eval=F}
map_data(region='county')

blank_layer <- list(
  title = "",
  showgrid = F,
  showticklabels = F,
  zeroline = F)

map_data("county") %>%
  filter(region == 'california') %>%
  group_by(group) %>%
  plot_ly(
    x = ~long,
    y = ~lat,
    fillcolor = 'white',
    hoverinfo = "none") %>%
  add_polygons(
    line = list(color = 'black', width = 0.5)) %>%
  layout(
    xaxis = blank_layer,
    yaxis = blank_layer)




#### Discrete

```{r data, eval=FALSE}
# data available at https://github.com/polygraph-cool/smoothing_tutorial/blob/master/us_county_hs_only.zip
data('CanWeather', package = 'gamair')
```


# References

[^Xlme]: All the same variables in the lme output start with X. This is more to avoid confusion in the functions behind the scenes.
[^timefits]: I don't show it to keep the plot clean, but the fitted values are essentially the same.
[^rforeverything]: Because of course there is an R package just for New Zealand census data.